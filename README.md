## â™»ï¸ TrashNet Binary Classifier
### EvaluaciÃ³n III-IV Machine Learning TIEL26-101-8V-A

**âœ… PROYECTO COMPLETADO Y EJECUTADO EXITOSAMENTE (Deep Learning + ProducciÃ³n)**

---

## ğŸ“˜ InformaciÃ³n AcadÃ©mica
- Estudiante: Christian SantibÃ¡Ã±ez MartÃ­nez  
- Profesor: Felipe OyarzÃºn  
- InstituciÃ³n: INACAP  
- Fecha: 15 de Diciembre, 2025  

---

## ğŸ“– DescripciÃ³n del Proyecto
Proyecto de **Deep Learning aplicado a visiÃ³n por computador**, cuyo objetivo es clasificar imÃ¡genes de residuos en dos clases: **Reciclable (1)** y **No Reciclable (0)** usando el dataset pÃºblico **TrashNet**. 

El trabajo integra todo el ciclo de vida de un modelo de Deep Learning:
- ConstrucciÃ³n de un clasificador binario basado en **CNN pre-entrenadas** (ResNet-18 / MobileNetV3-Small) con **transfer learning y fine-tuning**.
- GeneraciÃ³n y aumento del conjunto de datos (re-etiquetado binario, splits estratificados y data augmentation geomÃ©trico/fotomÃ©trico).
- Entrenamiento, validaciÃ³n cruzada y evaluaciÃ³n final en un conjunto de test independiente.
- **ExportaciÃ³n del modelo a ONNX** y desarrollo de un **servicio de inferencia con FastAPI**, pensado para producciÃ³n en entornos locales o cloud.
- ConfiguraciÃ³n de **integraciÃ³n continua (CI)** con GitHub Actions para validar automÃ¡ticamente la construcciÃ³n del modelo y la exportaciÃ³n a ONNX.

---

## ğŸ¯ Objetivos de Aprendizaje
- DiseÃ±ar e implementar un modelo de **Deep Learning** basado en redes convolucionales y transferencia de aprendizaje para clasificaciÃ³n de imÃ¡genes.  
- Configurar y comparar estrategias de **fine-tuning** (entrenamiento completo del backbone vs. entrenamiento solo de la cabeza).  
- Generar y aumentar un conjunto de datos para Deep Learning, aplicando **splits estratificados y data augmentation** para mejorar la generalizaciÃ³n.  
- Evaluar rigurosamente el desempeÃ±o del modelo (Accuracy, Precision, Recall, F1, ROC-AUC) mediante validaciÃ³n cruzada y test independiente.  
- Implementar el modelo en **modo de producciÃ³n** usando exportaciÃ³n a ONNX y un servicio de inferencia con FastAPI, considerando eficiencia y uso de recursos.  
- Incorporar una **integraciÃ³n continua bÃ¡sica (CI)** que ejecute tests sobre el modelo y el proceso de exportaciÃ³n, asegurando reproducibilidad y mantenibilidad del proyecto.

---

## ğŸ—ï¸ Modelo y ConfiguraciÃ³n (Deep Learning)
```
Entrada (224x224 RGB) â†’ CNN pre-entrenada (ResNet-18 / MobileNetV3-Small)
PÃ©rdida: BCEWithLogitsLoss (con class weights)
Optimizador: AdamW (lr=3e-4, wd=1e-4) + Cosine LR / ReduceLROnPlateau
Early Stopping: paciencia=5

Estrategia de fine-tuning (config.yaml â†’ training.finetune_strategy):
- "full": entrena todo el backbone (fine-tuning completo)
- "head": congela el backbone y entrena solo la Ãºltima capa (head-only)
```

---

## ğŸ“Š Dataset
- Origen: TrashNet (MIT).  
- Clases originales (6): glass, paper, cardboard, plastic, metal, trash.  
- Mapeo binario: reciclable={glass,paper,cardboard,plastic,metal} â†’ 1; no reciclable={trash} â†’ 0.  
- Estructura esperada: `data/raw/dataset-resized/<clase>/*.jpg`.  
- CSV con splits: `data/interim/labels.csv` (2527 filas; train/val/test â‰ˆ 70/15/15).

---

## âš™ï¸ CÃ³mo Ejecutar el Proyecto
1) Crear entorno e instalar dependencias (Windows/PowerShell):
```powershell
python -m venv .venv
\.\.venv\Scripts\Activate.ps1
python -m pip install --upgrade pip
pip install -r requirements.txt
```
2) Preparar dataset y generar CSV:
```powershell
python -m src.data.prepare_dataset --raw_dir data/raw/dataset-resized --out_csv data/interim/labels.csv --test_size 0.15 --val_size 0.15 --seed 42
```
3) Herramienta de etiquetado (opcional):
```powershell
streamlit run tools/label_tool_streamlit.py -- --csv data/interim/labels.csv
```
4) Entrenamiento (Deep Learning):
```powershell
python -m src.train.train --config config.yaml
```
5) ValidaciÃ³n cruzada (5-fold):
```powershell
python -m src.train.cross_validate --config config.yaml
```
6) Figuras para el informe (curvas + matriz + ROC):
```powershell
python -m src.train.evaluate --exp_dir experiments/exp_YYYYMMDD_HHMMSS --config config.yaml --out_dir report/figuras
```

7) Exportar el mejor modelo a ONNX (para producciÃ³n):
```powershell
python -m src.models.export_onnx --exp_dir experiments/exp_YYYYMMDD_HHMMSS --config config.yaml
```
Genera `experiments/exp_YYYYMMDD_HHMMSS/model.onnx` usando la configuraciÃ³n guardada.

8) Servicio de inferencia (FastAPI + ONNX, local):
```powershell
uvicorn serving.api_fastapi:app --reload
```
- Ir a `http://127.0.0.1:8000/` para ver el estado del servicio.
- Ir a `http://127.0.0.1:8000/docs` para abrir la UI automÃ¡tica (Swagger) y probar el endpoint `POST /predict` subiendo imÃ¡genes.

---

## ğŸ“ˆ Resultados del Proyecto
### ValidaciÃ³n Cruzada (5 folds)
- Accuracy: 0.9423 Â± 0.0115  
- Precision macro: 0.7435 Â± 0.0255  
- Recall macro: 0.9490 Â± 0.0153  
- F1 macro: 0.8068 Â± 0.0233  
- ROC-AUC: 0.9818 Â± 0.0082  

### Test Final (modelo entrenado)
- Accuracy: 0.9658  
- F1 macro: 0.8398  
- ROC-AUC: 0.9674  

---

## ğŸ“‚ Estructura del Proyecto
```
EvaluaciÃ³n II Machine Learning TIEL26-101-8V-A/
â”œâ”€â”€ config.yaml                       # ConfiguraciÃ³n del pipeline
â”œâ”€â”€ requirements.txt                  # Dependencias
â”œâ”€â”€ README.md                         # Este documento
â”œâ”€â”€ .gitignore                        # ConfiguraciÃ³n de Git
â”œâ”€â”€ predicciones_trash.csv            # CSV de inferencia por carpeta [GENERADO]
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # Colocar TrashNet (IGNORADO)
â”‚   â”œâ”€â”€ interim/                      # CSV con splits
â”‚   â””â”€â”€ processed/                    # Procesados (IGNORADO)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                         # prepare_dataset, dataset, augmentations
â”‚   â”œâ”€â”€ models/                       # build_model, export_onnx
â”‚   â”œâ”€â”€ train/                        # train, cross_validate, evaluate
â”‚   â””â”€â”€ utils/                        # seed, metrics, config
â”‚
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ label_tool_streamlit.py       # Herramienta de etiquetado
â”‚
â”œâ”€â”€ serving/
â”‚   â””â”€â”€ api_fastapi.py                # Servicio de inferencia (FastAPI + ONNX)
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_model_and_export.py      # Tests: forma del modelo + exportaciÃ³n ONNX
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml                    # CI (GitHub Actions) ejecuta pytest en cada push/PR
â”‚
â”œâ”€â”€ experiments/                      # Artefactos (pesos ignorados; JSON visibles)
â”‚
â””â”€â”€ report/
    â””â”€â”€ figuras/                      # ImÃ¡genes para el informe
```

---

## ğŸ” AnÃ¡lisis de Errores (resumen)
- Recall macro alto sugiere buena sensibilidad en ambas clases.  
- Precision macro menor indica algunos falsos positivos (umbral ajustable).  
- Oportunidad: threshold tuning o focal loss segÃºn requerimientos.

---

## ğŸ“Š Visualizaciones Incluidas
1. `report/figuras/loss_curves.png` â€” Curvas de pÃ©rdida train/val.  
2. `report/figuras/val_metrics_curves.png` â€” Accuracy/F1 val por Ã©poca.  
3. `report/figuras/confusion_matrix_test.png` â€” Matriz de confusiÃ³n test.  
4. `report/figuras/roc_curve_test.png` â€” Curva ROC test.  

---

## ğŸ§¾ Reproducibilidad
- ConfiguraciÃ³n centralizada en `config.yaml`.  
- Semillas fijadas (`src/utils/seed.py`).  
- `experiments/`: JSON visibles; pesos `.pt/.pth` ignorados.  
- ExportaciÃ³n a ONNX reproducible vÃ­a `src/models/export_onnx.py`.  
- CI mÃ­nima en GitHub Actions (`.github/workflows/ci.yml`) que instala dependencias y ejecuta `pytest`.

---

## ğŸš€ Demo rÃ¡pida (inferencia)
Usa el mejor modelo entrenado para predecir si una imagen es reciclable.

1) Imagen Ãºnica:
```powershell
python -m src.train.predict --exp_dir experiments/exp_YYYYMMDD_HHMMSS --image "data/raw/dataset-resized/plastic/plastic390.jpg"
```

2) Carpeta completa (genera CSV opcional):
```powershell
python -m src.train.predict --exp_dir experiments/exp_YYYYMMDD_HHMMSS --dir "data/raw/dataset-resized/trash" --csv_out "predicciones_trash.csv"
```

Opcionales:
- `--threshold 0.5` para ajustar el umbral de clasificaciÃ³n.
- `--image_size 224` para cambiar el tamaÃ±o de entrada.

---

## ğŸ“š CitaciÃ³n y Licencias
- TrashNet â€” MIT License (https://huggingface.co/datasets/garythung/trashnet).  
- Este proyecto con fines acadÃ©micos.

